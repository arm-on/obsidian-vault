![[backdoor-attack.png]]
## <font color="#00b0f0">Key Notes</font>

- The first backdoor attack in the machine learning systems
- Only around 50 poisoning samples, ASR of above 90%
- The first work to show that a data poisoning attack can create physically implementable backdoors without touching the training process.
- Blended Backdoor (Baseline)

## <font color="#00b0f0">Method</font>

![[Pasted image 20251003190654.png]]
![[Pasted image 20251003190757.png]]
